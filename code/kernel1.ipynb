{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9619b018-f7a0-4d13-90b4-f769a8906003",
    "_uuid": "cac9915711fdcec7e8eb6431fd8dcae21649b6aa"
   },
   "source": [
    "**Building a strong image classification model from less data**\n",
    "\n",
    "The implementation is a slight variation of the one in https://gist.github.com/fchollet/0830affa1f7f19fd47b06d4cf89ed44d\n",
    "\n",
    "Mainly, in this kernel , the method flow(x,y) is used whereas, in the above gist, method flow_from_directory(directory) is used.\n",
    "For more info, you can refer https://keras.io/preprocessing/image/\n",
    "\n",
    "The change is made to have an appropriate kernel to deal with the way data is structured in kaggle. Appropriate changes in other parts of the source code is also done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e10726c1-a487-4d89-bf8f-7ff532592440",
    "_uuid": "16fefbb9857aead05fe80ecbf3ffbabfae4fca22"
   },
   "source": [
    "**Perform the necessary imports.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "4f4ac6a4-708c-46ab-8269-e01978300bde",
    "_uuid": "49532c85c74dee05663bd7eda324d3df493c60ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, re, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fa55078-4136-47a1-9914-1cac54eec440",
    "_uuid": "d57ed5db51e8c287e62a8b40d264c42ca64a9ecf"
   },
   "source": [
    "**Data dimensions and paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "25980d83-1f66-420b-a1dc-501699c3d707",
    "_uuid": "2eb716c4e9ad7d0bd7293f0f156b5a751263b800"
   },
   "outputs": [],
   "source": [
    "img_width = 150\n",
    "img_height = 150\n",
    "TRAIN_DIR = './input/train/'\n",
    "TEST_DIR = './input/test/'\n",
    "train_images_dogs_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "test_images_dogs_cats = [TEST_DIR+i for i in os.listdir(TEST_DIR)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7fd765e1-e4e1-4b59-b7b2-33336afd4848",
    "_uuid": "505895b51eb3ed5a1dee521c9adc0864639d0b96"
   },
   "source": [
    "**Helper function to sort the image files based on the numeric value in each file name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "a11beea5-afc8-42ac-9688-c9bd45ea19aa",
    "_uuid": "775ea273467ff9d32fbf2c1b2158b57f473618b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4c8b492-315c-4c38-9b1e-32c05e368027",
    "_uuid": "11a7c4072cdedd8f5b79d4bfcec3d1f31d448404"
   },
   "source": [
    "**Sort the traning set. Use 1300 images each of cats and dogs instead of all 25000 to speed up the learning process.**\n",
    "\n",
    "**Sort the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "001b4ea8-a12f-4290-9a0d-6990b7deb2f7",
    "_uuid": "22c6c18de15a48f12e9f2120ea56f6e603bc6329",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_dogs_cats.sort(key=natural_keys)\n",
    "train_images_dogs_cats = train_images_dogs_cats[0:1300] + train_images_dogs_cats[12500:13800] \n",
    "\n",
    "test_images_dogs_cats.sort(key=natural_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "58d15bea-7674-46ff-ba0d-af6a920590be",
    "_uuid": "5d3a332070aadd998dcb3ac506f086d1cbe37b20"
   },
   "source": [
    "**Now the images have to be represented in numbers. For this, using the openCV library read and resize the image.  **\n",
    "\n",
    "**Generate labels for the supervised learning set.**\n",
    "\n",
    "**Below is the helper function to do so.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "be6eb2de-4302-4731-ba11-75cdb114a0df",
    "_uuid": "5dcd4727d558b622fa5533f203834e86c758dace",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n",
    "    \n",
    "    for i in list_of_images:\n",
    "        if 'dog' in i:\n",
    "            y.append(1)\n",
    "        elif 'cat' in i:\n",
    "            y.append(0)\n",
    "        #else:\n",
    "            #print('neither cat nor dog name present in images')\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eaddc700-7124-4526-9615-46e96144af58",
    "_uuid": "c42578104846f709ec064b3fa82c861597dd18f1"
   },
   "source": [
    "**Generate X and Y using the helper function above**\n",
    "\n",
    "**Since K.image_data_format() is channel_last,  input_shape to the first keras layer will be (img_width, img_height, 3). '3' since it is a color image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "9add14aa-3cd6-4160-a3f3-20a2f6b61af9",
    "_uuid": "0111553c02dd7e4d622aeb65c3d307038f32f000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "X, Y = prepare_data(train_images_dogs_cats)\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "110e7b06-d53d-4be4-ae4f-ca62a9beed89",
    "_uuid": "13d1080aa11311bd3fe29857f621503797111080"
   },
   "source": [
    "**Split the data set containing 2600 images into 2 parts, training set and validation set. Later, you will see that accuracy and loss on the validation set will also be reported while fitting the model using training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "6a94930d-9c33-4361-ba3d-ef1f29707bce",
    "_uuid": "26eea9b27bcbf6a0ca3eba6f91cf5cace580f442",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First split the data in two sets, 80% for training, 20% for Val/Test)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "34977dad-9c51-4946-a465-d79138306b03",
    "_uuid": "c5e3ba21cd44491307721204db024166a5028499",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_samples = len(X_train)\n",
    "nb_validation_samples = len(X_val)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f4cfc349-2ad8-46f8-9816-80b086401eff",
    "_uuid": "6b998b641c185a10e809d95762b57a13a0065f56"
   },
   "source": [
    "**We will be using the Sequential model from Keras to form the Neural Network. Sequential Model is  used to construct simple models with linear stack of layers. **\n",
    "\n",
    "**More info on Sequential model and Keras in general at https://keras.io/getting-started/sequential-model-guide/ and https://github.com/keras-team/keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "e72ad7e4-0692-4dd2-a49f-47640caf2e52",
    "_uuid": "f27c9488fc9767db7ef6beb75b45959852e6a018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513.0\n",
      "Trainable params: 1,212,513.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3342dd4d-9dc1-454a-9f09-0674c8ac41d1",
    "_uuid": "cc941a4d3d7cef29c74b4c28bb8849c2ebae5a40"
   },
   "source": [
    "**This is the augmentation configuration we will use for training and validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "cf7cd57a-4532-4d79-a2dc-431b7bf174eb",
    "_uuid": "8a40cd117597246908aa7ef02172d08096548ba2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1fffe8d6-e21b-4354-8313-323bfbb517da",
    "_uuid": "c78ba8af934502e7a736e1671a4ef73452ace722"
   },
   "source": [
    "**Prepare generators for training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "36388127-2d62-4aac-999e-04decf9bba30",
    "_uuid": "3b91d6026f7a71f7a5f8347032fd03c6dc929337",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "00cab697-e7c4-41a3-9014-1f7406c2d104",
    "_uuid": "bf95bd03922a7449939b135c632079968487324f"
   },
   "source": [
    "**Start training the model!**\n",
    "\n",
    "**For better accuracy and lower loss, we are using an epoch of 30. Epoch value can be increased for better results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "446727ad-a903-45c2-bf87-97152984baa9",
    "_uuid": "d46dd6f0d43b62a27e92fe1c0088d787709fc584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "130/130 [==============================] - 8s - loss: 0.7058 - acc: 0.5067 - val_loss: 0.6884 - val_acc: 0.5977\n",
      "Epoch 2/30\n",
      "130/130 [==============================] - 7s - loss: 0.6746 - acc: 0.5659 - val_loss: 0.6300 - val_acc: 0.6387\n",
      "Epoch 3/30\n",
      "130/130 [==============================] - 7s - loss: 0.6285 - acc: 0.6567 - val_loss: 0.6020 - val_acc: 0.6582\n",
      "Epoch 4/30\n",
      "130/130 [==============================] - 7s - loss: 0.6062 - acc: 0.6937 - val_loss: 0.5976 - val_acc: 0.6641\n",
      "Epoch 5/30\n",
      "130/130 [==============================] - 7s - loss: 0.5901 - acc: 0.7029 - val_loss: 0.5715 - val_acc: 0.7324\n",
      "Epoch 6/30\n",
      "130/130 [==============================] - 7s - loss: 0.5707 - acc: 0.7236 - val_loss: 0.5817 - val_acc: 0.7012\n",
      "Epoch 7/30\n",
      "130/130 [==============================] - 7s - loss: 0.5464 - acc: 0.7322 - val_loss: 0.5462 - val_acc: 0.7227\n",
      "Epoch 8/30\n",
      "130/130 [==============================] - 7s - loss: 0.5420 - acc: 0.7341 - val_loss: 0.5332 - val_acc: 0.7305\n",
      "Epoch 9/30\n",
      "130/130 [==============================] - 7s - loss: 0.5314 - acc: 0.7361 - val_loss: 0.5643 - val_acc: 0.7090\n",
      "Epoch 10/30\n",
      "130/130 [==============================] - 7s - loss: 0.5230 - acc: 0.7639 - val_loss: 0.5447 - val_acc: 0.7109\n",
      "Epoch 11/30\n",
      "130/130 [==============================] - 7s - loss: 0.5082 - acc: 0.7538 - val_loss: 0.8448 - val_acc: 0.6426\n",
      "Epoch 12/30\n",
      "130/130 [==============================] - 7s - loss: 0.5014 - acc: 0.7659 - val_loss: 0.5411 - val_acc: 0.7305\n",
      "Epoch 13/30\n",
      "130/130 [==============================] - 7s - loss: 0.4993 - acc: 0.7668 - val_loss: 0.5261 - val_acc: 0.7422\n",
      "Epoch 14/30\n",
      "130/130 [==============================] - 7s - loss: 0.4908 - acc: 0.7769 - val_loss: 0.4915 - val_acc: 0.7559\n",
      "Epoch 15/30\n",
      "130/130 [==============================] - 7s - loss: 0.4851 - acc: 0.7827 - val_loss: 0.5025 - val_acc: 0.7500\n",
      "Epoch 16/30\n",
      "130/130 [==============================] - 7s - loss: 0.4723 - acc: 0.7870 - val_loss: 0.5325 - val_acc: 0.7285\n",
      "Epoch 17/30\n",
      "130/130 [==============================] - 7s - loss: 0.4586 - acc: 0.7798 - val_loss: 0.4959 - val_acc: 0.7559\n",
      "Epoch 18/30\n",
      "130/130 [==============================] - 7s - loss: 0.4595 - acc: 0.7938 - val_loss: 0.5118 - val_acc: 0.7617\n",
      "Epoch 19/30\n",
      "130/130 [==============================] - 7s - loss: 0.4528 - acc: 0.7976 - val_loss: 0.5463 - val_acc: 0.7578\n",
      "Epoch 20/30\n",
      "130/130 [==============================] - 7s - loss: 0.4644 - acc: 0.8000 - val_loss: 0.5166 - val_acc: 0.7480\n",
      "Epoch 21/30\n",
      "130/130 [==============================] - 7s - loss: 0.4470 - acc: 0.8072 - val_loss: 0.4949 - val_acc: 0.7695\n",
      "Epoch 22/30\n",
      "130/130 [==============================] - 7s - loss: 0.4473 - acc: 0.7952 - val_loss: 0.5200 - val_acc: 0.7441\n",
      "Epoch 23/30\n",
      "130/130 [==============================] - 7s - loss: 0.4620 - acc: 0.8053 - val_loss: 0.5089 - val_acc: 0.7734\n",
      "Epoch 24/30\n",
      "130/130 [==============================] - 7s - loss: 0.4355 - acc: 0.7971 - val_loss: 0.5729 - val_acc: 0.7559\n",
      "Epoch 25/30\n",
      "130/130 [==============================] - 7s - loss: 0.4436 - acc: 0.7990 - val_loss: 0.4749 - val_acc: 0.7715\n",
      "Epoch 26/30\n",
      "130/130 [==============================] - 7s - loss: 0.4460 - acc: 0.8019 - val_loss: 0.4742 - val_acc: 0.7852\n",
      "Epoch 27/30\n",
      "130/130 [==============================] - 7s - loss: 0.4324 - acc: 0.8024 - val_loss: 0.6036 - val_acc: 0.7324\n",
      "Epoch 28/30\n",
      "130/130 [==============================] - 7s - loss: 0.4419 - acc: 0.8096 - val_loss: 0.4791 - val_acc: 0.7578\n",
      "Epoch 29/30\n",
      "130/130 [==============================] - 7s - loss: 0.4302 - acc: 0.8144 - val_loss: 0.5217 - val_acc: 0.7637\n",
      "Epoch 30/30\n",
      "130/130 [==============================] - 7s - loss: 0.4382 - acc: 0.8091 - val_loss: 0.5255 - val_acc: 0.7695\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cf363841-697a-4b38-9415-a1f57b8f16cb",
    "_uuid": "8d4932c5555b6274a8a0b16c3fb770c003a1d380"
   },
   "source": [
    "**Well done for a small training set and a small Epoch! Accuracy on the training set is close to 84% while on the validation set is close to 79%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e5ba296f-049f-407a-ae30-22a2226d4810",
    "_uuid": "3d679de7accbe4df7daac93969900f4f2c8c3d75"
   },
   "source": [
    "**Saving the model in Keras is simple as this! ** \n",
    "\n",
    "**It is quite helpful for reuse.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "32aa2713-f32d-458e-9f9c-8c0dcb5f50f0",
    "_uuid": "c3dc5f39f8e8227b6fbc99dab80af96a48aa9c1b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('model_wieghts.h5')\n",
    "model.save('model_keras.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7ed718a4-826e-4b83-9f2e-2156f6a75f45",
    "_uuid": "a1889aed06ff0c9d9a4f5095cc38649c2606dbca"
   },
   "source": [
    "**Time to predict classification using the model on the test set.**\n",
    "\n",
    "**Generate X_test and Y_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "490f5e45-eefd-4a46-b3bd-3e7e09cf695d",
    "_uuid": "f807eefa26fcb70a4b9f7eb8b6c06e50109f65fc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, Y_test = prepare_data(test_images_dogs_cats) #Y_test in this case will be []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8a84efef-c2a3-4cda-a3a0-a6c2d6032238",
    "_uuid": "c5c594867c18faeb5053bc2c819f78514f07a493"
   },
   "source": [
    "**This is the augmentation configuration we will use for testing. Only rescaling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "a2c141c2-ec9e-4eab-8ea8-fa1a7485e506",
    "_uuid": "33af89c39a57edfb49dca2a33c159c96e7d63fe2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db815324-2ca3-49ce-a005-a1578f179092",
    "_uuid": "3c074c8a7974d1c2b01d07d37a2f3bab88fc9951"
   },
   "source": [
    "**Prepare generator for test set and start predicting on it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "112ff470-4976-496c-bb0c-2c6eddddb528",
    "_uuid": "49a4cc7684dfde31cd2dfd2921bfa15bfae19672"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 36s    \n"
     ]
    }
   ],
   "source": [
    "test_generator = val_datagen.flow(np.array(X_test), batch_size=batch_size)\n",
    "prediction_probabilities = model.predict_generator(test_generator, steps=len(X_test)//batch_size+1,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae9bb1ac-91a2-43c4-a57d-e87651c4d3e4",
    "_uuid": "e299a1c8f9a927a2896a6dacb016bba9c83d0eea"
   },
   "source": [
    "**Generate .csv for submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "bc3fada0-c12a-4b36-a3a1-eaa7195e9b19",
    "_uuid": "75ff4f7fa16b6fc9758bcea0dd2107b65740cfda",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = range(1, len(test_images_dogs_cats) + 1)\n",
    "solution = pd.DataFrame({\"id\": counter, \"label\":list(prediction_probabilities)})\n",
    "cols = ['label']\n",
    "\n",
    "for col in cols:\n",
    "    solution[col] = solution[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)\n",
    "\n",
    "solution.to_csv(\"dogsVScats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "edaa9c27-5d0a-4488-b67b-525f7f71377f",
    "_uuid": "f333a76d6514546f410d0e2679431515681bb87f"
   },
   "source": [
    "**Kindly upvote if you find this kernel useful**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
